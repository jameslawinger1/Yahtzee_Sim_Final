{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d0472f",
   "metadata": {},
   "source": [
    "Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0973e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "results_dir = '../results'\n",
    "plots_dir = '../plots'\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Load CSVs\n",
    "score_files = glob.glob(os.path.join(results_dir, \"*_scores.csv\"))\n",
    "scores = {}\n",
    "for file in score_files:\n",
    "    name = os.path.basename(file).replace(\"_scores.csv\", \"\")\n",
    "    df = pd.read_csv(file)\n",
    "    scores[name] = df['score']\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be7d2450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: c:\\Users\\jlawi\\OneDrive - Georgia Institute of Technology\\Documents\\Simulation Project\\analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a05e20",
   "metadata": {},
   "source": [
    "Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08f805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=0, step=1)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_4116\\3392117497.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m         \u001b[33m\"95% CI\"\u001b[39m: ci\n\u001b[32m     15\u001b[39m     })\n\u001b[32m     16\u001b[39m summary_df = pd.DataFrame(summary)\n\u001b[32m     17\u001b[39m print(summary_df.columns)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m summary_df = pd.DataFrame(summary).sort_values(\u001b[33m\"Mean\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     19\u001b[39m summary_df\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7185\u001b[39m             )\n\u001b[32m   7186\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m len(by):\n\u001b[32m   7187\u001b[39m             \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[32m   7188\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m7189\u001b[39m             k = self._get_label_or_level_values(by[\u001b[32m0\u001b[39m], axis=axis)\n\u001b[32m   7190\u001b[39m \n\u001b[32m   7191\u001b[39m             \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[32m   7192\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'Mean'"
     ]
    }
   ],
   "source": [
    "summary = []\n",
    "for name, data in scores.items():\n",
    "    mean = round(data.mean(), 2)\n",
    "    median = data.median()\n",
    "    std = round(data.std(), 2)\n",
    "    ci = round(1.96 * std / math.sqrt(len(data)), 2)\n",
    "    summary.append({\n",
    "        \"Strategy\": name,\n",
    "        \"Mean\": mean,\n",
    "        \"Median\": median,\n",
    "        \"Std Dev\": std,\n",
    "        \"Min\": data.min(),\n",
    "        \"Max\": data.max(),\n",
    "        \"95% CI\": ci\n",
    "    })\n",
    "summary_df = pd.DataFrame(summary).sort_values(\"Mean\", ascending=False)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2363fc",
   "metadata": {},
   "source": [
    "Histogram and Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5965e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, data in scores.items():\n",
    "    plt.figure()\n",
    "    plt.hist(data, bins=30)\n",
    "    plt.title(f\"{name} – Score Distribution\")\n",
    "    plt.xlabel(\"Total Score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.boxplot(scores.values(), labels=scores.keys())\n",
    "plt.title(\"Strategy Comparison – Boxplot\")\n",
    "plt.ylabel(\"Total Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1b6431",
   "metadata": {},
   "source": [
    "Pairwise t-Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pairwise t-tests (p-values):\")\n",
    "names = list(scores.keys())\n",
    "for i in range(len(names)):\n",
    "    for j in range(i + 1, len(names)):\n",
    "        s1, s2 = names[i], names[j]\n",
    "        _, p = ttest_ind(scores[s1], scores[s2], equal_var=False)\n",
    "        print(f\"{s1} vs {s2}: p = {p:.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01ae84f",
   "metadata": {},
   "source": [
    "Cohen's d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCohen's d (effect size vs Dice-Driven):\")\n",
    "base = \"Dice-Driven\"\n",
    "for other in scores:\n",
    "    if other != base:\n",
    "        m1, m2 = scores[base].mean(), scores[other].mean()\n",
    "        s1, s2 = scores[base].std(), scores[other].std()\n",
    "        pooled_std = ((s1**2 + s2**2) / 2)**0.5\n",
    "        d = (m1 - m2) / pooled_std\n",
    "        print(f\"{base} vs {other}: d = {d:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
